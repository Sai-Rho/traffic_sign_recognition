{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Traffic Signs Recognition?\n",
    "There are several different types of traffic signs like speed limits, no entry, traffic signals, turn left or right, children crossing, no passing of heavy vehicles, etc. Traffic signs classification is the process of identifying which class a traffic sign belongs to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim of the project\n",
    "We have to build a Deep Neural Network model that can classify traffic signs present in the image into different categories. With this model, we should be able to read and understand traffic signs which are a very important task for all autonomous vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary libraries\n",
    "\n",
    "Importing data and preprocessing\n",
    "\n",
    "Converting image and label lists into numpy arrays\n",
    "\n",
    "Splitting data and labels into training and testing dataset\n",
    "\n",
    "CNN Model Building\n",
    "\n",
    "Compilation of the model\n",
    "\n",
    "fitting of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info on data \n",
    "The dataset contains more than 50,000 images of different traffic signs.\n",
    "\n",
    "It is further classified into 43 different classes.\n",
    "\n",
    "The ‘train’ folder contains 43 folders each representing a different class. The range of the folder is from 0 to 42. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "categories = 43\n",
    "height = 30\n",
    "width = 30\n",
    "curr_path = os.getcwd()                 # The method os. getcwd() in Python returns the current working directory of a process. \n",
    "\n",
    "for i in range(categories):\n",
    "    path = os.path.join(curr_path,'Dataset/train',str(i))       #joins one or more path components\n",
    "    images = os.listdir(path)                                   #lists files and directories in the given path \n",
    "    for a in images:    \n",
    "        try:\n",
    "            image = Image.open(path + '//'+ a)                  #opening other image file     \n",
    "            image = image.resize((height,width))                #resizing the image to maintain uniform\n",
    "            image = np.array(image)                             #getting array of images using numpy\n",
    "            data.append(image)                                  #appending images data to data list\n",
    "            labels.append(i)                                    #appending the labels list\n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting image and label lists into numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the data and label list into numpy arrays for feeding to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)                          #data list into numpy array\n",
    "labels = np.array(labels)                      #label list into numpy array\n",
    "print(data.shape, labels.shape)                #shape of data and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The shape of data is (39209, 30, 30, 3)\n",
    "\n",
    "which means that there are 39209 images \n",
    "\n",
    "image size 30×30 pixels \n",
    "\n",
    "The last 3 defines the data contains colored images i,e (RGB value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data and labels into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31367, 30, 30, 3) (7842, 30, 30, 3) (31367,) (7842,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,          #train_test_split() method to split training and testing data\n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=30)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)    # shape of training and testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test size is 0.2 i,e 20 % data\n",
    "### For training\n",
    "The shape of data is (31367, 30, 30, 3)\n",
    "\n",
    "which means that there are 31367 images\n",
    "\n",
    "image size 30×30 pixels\n",
    "\n",
    "The last 3 defines the data contains colored images i,e (RGB value).\n",
    "\n",
    "### for testing \n",
    "The shape of data is (7842, 30, 30, 3)\n",
    "\n",
    "which means that there are 7842 images\n",
    "\n",
    "image size 30×30 pixels\n",
    "\n",
    "The last 3 defines the data contains colored images i,e (RGB value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the labels\n",
    "to_categorical Converts a class vector (integers) to binary class matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "conv2d() is the TensorFlow function you can use to build a 2D convolutional layer as part of your CNN architecture.\n",
    "\n",
    "ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.\n",
    "\n",
    "Max pooling is a type of operation that is typically added to CNNs following individual convolutional layers. When added to a model, max pooling reduces the dimensionality of images by reducing the number of pixels in the output from the previous convolutional layer.\n",
    "\n",
    "Dropout is a technique used to prevent a model from overfitting. Dropout works by randomly setting the outgoing edges of hidden units (neurons that make up hidden layers) to 0 at each update of the training phase.\n",
    "\n",
    "Dense layer is a fully connected layer, meaning all the neurons in a layer are connected to those in the next layer.\n",
    "\n",
    "The softmax function is used as the activation function in the output layer of neural network models that predict a multinomial probability distribution. That is, softmax is used as the activation function for multi-class classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(5,5), \n",
    "                 activation='relu', \n",
    "                 input_shape=X_train.shape[1:]))\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(5,5), \n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Flatten())       \n",
    "\n",
    "model.add(Dense(190, activation='relu')) \n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile defines the loss function, the optimizer and the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trains the model for a fixed number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "491/491 [==============================] - 90s 181ms/step - loss: 4.3354 - accuracy: 0.1251 - val_loss: 1.7380 - val_accuracy: 0.5189\n",
      "Epoch 2/15\n",
      "491/491 [==============================] - 89s 181ms/step - loss: 1.7509 - accuracy: 0.4791 - val_loss: 0.8738 - val_accuracy: 0.7743\n",
      "Epoch 3/15\n",
      "491/491 [==============================] - 82s 167ms/step - loss: 1.1237 - accuracy: 0.6620 - val_loss: 0.6325 - val_accuracy: 0.8267\n",
      "Epoch 4/15\n",
      "491/491 [==============================] - 83s 168ms/step - loss: 0.8261 - accuracy: 0.7518 - val_loss: 0.4180 - val_accuracy: 0.8804\n",
      "Epoch 5/15\n",
      "491/491 [==============================] - 82s 167ms/step - loss: 0.6354 - accuracy: 0.8055 - val_loss: 0.2542 - val_accuracy: 0.9402\n",
      "Epoch 6/15\n",
      "491/491 [==============================] - 84s 171ms/step - loss: 0.5504 - accuracy: 0.8335 - val_loss: 0.2019 - val_accuracy: 0.9439\n",
      "Epoch 7/15\n",
      "491/491 [==============================] - 83s 169ms/step - loss: 0.4982 - accuracy: 0.8479 - val_loss: 0.1786 - val_accuracy: 0.9514\n",
      "Epoch 8/15\n",
      "491/491 [==============================] - 83s 169ms/step - loss: 0.4073 - accuracy: 0.8736 - val_loss: 0.1666 - val_accuracy: 0.9538\n",
      "Epoch 9/15\n",
      "491/491 [==============================] - 83s 168ms/step - loss: 0.4579 - accuracy: 0.8646 - val_loss: 0.1271 - val_accuracy: 0.9637\n",
      "Epoch 10/15\n",
      "491/491 [==============================] - 87s 178ms/step - loss: 0.3274 - accuracy: 0.9017 - val_loss: 0.1091 - val_accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "491/491 [==============================] - 81s 165ms/step - loss: 0.3043 - accuracy: 0.9048 - val_loss: 0.0986 - val_accuracy: 0.9708\n",
      "Epoch 12/15\n",
      "491/491 [==============================] - 81s 165ms/step - loss: 0.2927 - accuracy: 0.9127 - val_loss: 0.1055 - val_accuracy: 0.9693\n",
      "Epoch 13/15\n",
      "491/491 [==============================] - 81s 164ms/step - loss: 0.2965 - accuracy: 0.9111 - val_loss: 0.1042 - val_accuracy: 0.9718\n",
      "Epoch 14/15\n",
      "491/491 [==============================] - 84s 171ms/step - loss: 0.3236 - accuracy: 0.9058 - val_loss: 0.0823 - val_accuracy: 0.9764\n",
      "Epoch 15/15\n",
      "491/491 [==============================] - 83s 170ms/step - loss: 0.2471 - accuracy: 0.9291 - val_loss: 0.0751 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20d41460eb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size= 64, \n",
    "          epochs=15, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model got a 93% accuracy on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluate\n",
    "Evaluation is a process during development of the model to check whether the model is best fit for the given problem and corresponding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 4s - loss: 0.0751 - accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07513502240180969, 0.9780668020248413]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model,\n",
    "                                        tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 43), dtype=float32, numpy=\n",
       "array([[0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236329, 0.02236306, 0.02236306, 0.02236973,\n",
       "        0.02236379, 0.02237646, 0.02236306, 0.06072982, 0.02236306,\n",
       "        0.02236387, 0.02236306, 0.02236306],\n",
       "       [0.02238183, 0.02238183, 0.02238183, 0.02238191, 0.02238183,\n",
       "        0.02238187, 0.02238184, 0.02238183, 0.02238187, 0.02238184,\n",
       "        0.02238183, 0.02238187, 0.02238273, 0.022382  , 0.02238183,\n",
       "        0.02238183, 0.02238186, 0.02238183, 0.02238186, 0.02238183,\n",
       "        0.02238225, 0.02238183, 0.02238183, 0.02238184, 0.02238183,\n",
       "        0.02238202, 0.02238183, 0.02238183, 0.02238183, 0.02238183,\n",
       "        0.02238183, 0.02238183, 0.02238206, 0.02243712, 0.02245572,\n",
       "        0.05944131, 0.0225262 , 0.02238193, 0.02246673, 0.02238183,\n",
       "        0.0225425 , 0.02238227, 0.02238184],\n",
       "       [0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.06078678, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221],\n",
       "       [0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.06078678, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(X_test[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236306, 0.02236306, 0.02236306, 0.02236306,\n",
       "        0.02236306, 0.02236329, 0.02236306, 0.02236306, 0.02236973,\n",
       "        0.02236379, 0.02237646, 0.02236306, 0.06072982, 0.02236306,\n",
       "        0.02236387, 0.02236306, 0.02236306],\n",
       "       [0.02238183, 0.02238183, 0.02238183, 0.02238191, 0.02238183,\n",
       "        0.02238187, 0.02238184, 0.02238183, 0.02238187, 0.02238184,\n",
       "        0.02238183, 0.02238187, 0.02238273, 0.022382  , 0.02238183,\n",
       "        0.02238183, 0.02238186, 0.02238183, 0.02238186, 0.02238183,\n",
       "        0.02238225, 0.02238183, 0.02238183, 0.02238184, 0.02238183,\n",
       "        0.02238202, 0.02238183, 0.02238183, 0.02238183, 0.02238183,\n",
       "        0.02238183, 0.02238183, 0.02238206, 0.02243712, 0.02245572,\n",
       "        0.05944131, 0.0225262 , 0.02238193, 0.02246673, 0.02238183,\n",
       "        0.0225425 , 0.02238227, 0.02238184],\n",
       "       [0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.06078678, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221],\n",
       "       [0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.06078678, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221, 0.02236221, 0.02236221,\n",
       "        0.02236221, 0.02236221, 0.02236221]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TSR\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"TSR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "‘TensorFlow-GPU’",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
